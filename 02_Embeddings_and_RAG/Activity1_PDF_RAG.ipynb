{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 2222k  100 2222k    0     0  4923k      0 --:--:-- --:--:-- --:--:-- 4927k\n",
      "Collecting pip\n",
      "  Using cached pip-24.3.1-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting wheel\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Using cached pip-24.3.1-py3-none-any.whl (1.8 MB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Installing collected packages: wheel, pip\n",
      "Successfully installed pip-24.3.1 wheel-0.45.1\n",
      "pip 24.3.1 from /home/pkang/ai/aibootcamp/AIE5/02_Embeddings_and_RAG/.venv/lib/python3.11/site-packages/pip (python 3.11)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the virtual environment's Python executable path\n",
    "python_executable = sys.executable\n",
    "\n",
    "# Download get-pip.py\n",
    "!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
    "\n",
    "# Install pip using the virtual environment's Python\n",
    "!{python_executable} get-pip.py\n",
    "\n",
    "# Clean up\n",
    "!rm get-pip.py\n",
    "\n",
    "# Verify pip installation\n",
    "!{python_executable} -m pip --version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "# Install PyPDF2\n",
    "!{sys.executable} -m pip install PyPDF2\n",
    "\n",
    "# Imports\n",
    "from aimakerspace.text_utils import TextFileLoader, CharacterTextSplitter\n",
    "from aimakerspace.vectordatabase import VectorDatabase\n",
    "from aimakerspace.openai_utils.prompts import UserRolePrompt, SystemRolePrompt\n",
    "from aimakerspace.openai_utils.chatmodel import ChatOpenAI\n",
    "import asyncio\n",
    "import PyPDF2\n",
    "from typing import List\n",
    "import os\n",
    "\n",
    "# Enable async in Jupyter\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: PyPDF2 in ./.venv/lib/python3.11/site-packages (3.0.1)\n",
      "Collecting reportlab\n",
      "  Downloading reportlab-4.2.5-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: pillow>=9.0.0 in ./.venv/lib/python3.11/site-packages (from reportlab) (11.1.0)\n",
      "Collecting chardet (from reportlab)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Downloading reportlab-4.2.5-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Installing collected packages: chardet, reportlab\n",
      "Successfully installed chardet-5.2.0 reportlab-4.2.5\n",
      "Created test PDF: data/test.pdf\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "!{sys.executable} -m pip install PyPDF2 reportlab\n",
    "\n",
    "# Create a test PDF with some content\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import letter\n",
    "\n",
    "def create_test_pdf(filename: str):\n",
    "    \"\"\"Create a test PDF file with sample content.\"\"\"\n",
    "    c = canvas.Canvas(filename, pagesize=letter)\n",
    "    \n",
    "    # Page 1\n",
    "    c.drawString(100, 750, \"Test PDF Document - Page 1\")\n",
    "    c.drawString(100, 700, \"This is a sample PDF created for testing the RAG system.\")\n",
    "    c.drawString(100, 650, \"The Michael Eisner problem is discussed in this document.\")\n",
    "    c.drawString(100, 600, \"It relates to CEOs who hire weak executives in their former specialty.\")\n",
    "    \n",
    "    # Page 2\n",
    "    c.showPage()\n",
    "    c.drawString(100, 750, \"Test PDF Document - Page 2\")\n",
    "    c.drawString(100, 700, \"More information about executive hiring:\")\n",
    "    c.drawString(100, 650, \"1. Always hire strong executives\")\n",
    "    c.drawString(100, 600, \"2. Don't micromanage unnecessarily\")\n",
    "    c.drawString(100, 550, \"3. Focus on their strengths\")\n",
    "    \n",
    "    c.save()\n",
    "    print(f\"Created test PDF: {filename}\")\n",
    "\n",
    "# Create the test PDF\n",
    "create_test_pdf(\"data/test.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDFLoader:\n",
    "    \"\"\"Loads PDF files and converts them to text documents.\"\"\"\n",
    "    \n",
    "    def __init__(self, path: str):\n",
    "        self.path = path\n",
    "        self.documents = []\n",
    "        \n",
    "    def load_documents(self) -> List[str]:\n",
    "        \"\"\"Load PDF and convert to text documents.\"\"\"\n",
    "        if not os.path.exists(self.path):\n",
    "            print(f\"File not found: {self.path}\")\n",
    "            return []\n",
    "            \n",
    "        try:\n",
    "            with open(self.path, 'rb') as file:\n",
    "                # Create PDF reader object\n",
    "                pdf_reader = PyPDF2.PdfReader(file)\n",
    "                \n",
    "                # Extract text from each page\n",
    "                text = \"\"\n",
    "                for i, page in enumerate(pdf_reader.pages, 1):\n",
    "                    page_text = page.extract_text()\n",
    "                    text += f\"[Page {i}] {page_text}\\n\"\n",
    "                \n",
    "                self.documents.append(text)\n",
    "                print(f\"Successfully loaded PDF: {self.path}\")\n",
    "                print(f\"Number of pages: {len(pdf_reader.pages)}\")\n",
    "                \n",
    "            return self.documents\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading PDF {self.path}: {str(e)}\")\n",
    "            return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 1 text documents\n",
      "Successfully loaded PDF: data/test.pdf\n",
      "Number of pages: 2\n",
      "Loaded 1 PDF documents\n",
      "Created 374 chunks after splitting\n"
     ]
    }
   ],
   "source": [
    "# Load text documents\n",
    "text_loader = TextFileLoader(\"data/PMarcaBlogs.txt\")\n",
    "text_documents = text_loader.load_documents()\n",
    "print(f\"Loaded {len(text_documents)} text documents\")\n",
    "\n",
    "# Load PDF documents\n",
    "pdf_loader = PDFLoader(\"data/test.pdf\")\n",
    "pdf_documents = pdf_loader.load_documents()\n",
    "print(f\"Loaded {len(pdf_documents)} PDF documents\")\n",
    "\n",
    "# Combine all documents\n",
    "documents = text_documents + pdf_documents\n",
    "\n",
    "# Split documents into chunks\n",
    "text_splitter = CharacterTextSplitter()\n",
    "split_documents = text_splitter.split_texts(documents)\n",
    "print(f\"Created {len(split_documents)} chunks after splitting\")\n",
    "\n",
    "# Create and populate vector database\n",
    "vector_db = VectorDatabase()\n",
    "vector_db = asyncio.run(vector_db.abuild_from_list(split_documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What is the Michael Eisner problem?\n",
      "\n",
      "Top 3 relevant chunks:\n",
      "\n",
      "1. Relevance Score: 0.5650\n",
      "Source: PDF Document\n",
      "Text: [Page 1] Test PDF Document - Page 1\n",
      "This is a sample PDF created for testing the RAG system.\n",
      "The Michael Eisner problem is discussed in this document.\n",
      "It relates to CEOs who hire weak executives in th...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. Relevance Score: 0.5040\n",
      "Source: Text Document\n",
      "Text: ordingly.\n",
      "Seventh, when hiring the executive to run your former specialty, be\n",
      "careful you don’t hire someone weak on purpose.\n",
      "This sounds silly, but you wouldn’t believe how oaen it happens.\n",
      "The CEO w...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. Relevance Score: 0.4102\n",
      "Source: Text Document\n",
      "Text: ed?\n",
      "In reality — as opposed to Marc’s warped view of reality — it will\n",
      "be extremely helpful for Marc [if he were actually the CEO,\n",
      "which he is not] to meet with the new head of engineering daily\n",
      "when ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Query: What are the guidelines for hiring executives?\n",
      "\n",
      "Top 3 relevant chunks:\n",
      "\n",
      "1. Relevance Score: 0.6118\n",
      "Source: Text Document\n",
      "Text:  world,\n",
      "Part 8: Hiring, managing, promoting, and Dring executives 57\n",
      "competitive situation where they don’t start every day with\n",
      "80% market share. Back in the 80’s, you oaen heard, “never\n",
      "hire anyone ...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. Relevance Score: 0.5952\n",
      "Source: Text Document\n",
      "Text: vated manager or\n",
      "director running a function than an executive.\n",
      "Hiring an executive too quickly can lead to someone who is\n",
      "really expensive, sitting there in the middle of the room, doing\n",
      "very little....\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. Relevance Score: 0.5767\n",
      "Source: Text Document\n",
      "Text: ing on. Unless\n",
      "you’re paranoid — and, shockingly, I have met paranoid\n",
      "founders and CEOs, and not counting Andy Grove — you need\n",
      "to gather the data because you’re going to need to Xre the executive — i...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "Query: How many pages are in the test PDF?\n",
      "\n",
      "Top 3 relevant chunks:\n",
      "\n",
      "1. Relevance Score: 0.4569\n",
      "Source: PDF Document\n",
      "Text: [Page 1] Test PDF Document - Page 1\n",
      "This is a sample PDF created for testing the RAG system.\n",
      "The Michael Eisner problem is discussed in this document.\n",
      "It relates to CEOs who hire weak executives in th...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "2. Relevance Score: 0.2176\n",
      "Source: Text Document\n",
      "Text: her. Learn everything\n",
      "you can, then get the hell out of there before it’s too late.\n",
      "Ellen: How exactly will I know when that is?\n",
      "Nye: Ah. That’s for another walk.\n",
      "…and another post.\n",
      "126 The Pmarca Blo...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "3. Relevance Score: 0.2172\n",
      "Source: Text Document\n",
      "Text: ﻿\n",
      "The Pmarca Blog Archives\n",
      "(select posts from 2007-2009)\n",
      "Marc Andreessen\n",
      "copyright: Andreessen Horowitz\n",
      "cover design: Jessica Hagy\n",
      "produced using: Pressbooks\n",
      "Contents\n",
      "THE PMARCA GUIDE TO STARTUPS\n",
      "Part...\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "====================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def test_rag_system(query: str, k: int = 3):\n",
    "    \"\"\"Test the RAG system with a query.\"\"\"\n",
    "    print(f\"Query: {query}\\n\")\n",
    "    results = vector_db.search_by_text(query, k=k)\n",
    "    \n",
    "    print(f\"Top {k} relevant chunks:\")\n",
    "    for i, (text, score) in enumerate(results, 1):\n",
    "        print(f\"\\n{i}. Relevance Score: {score:.4f}\")\n",
    "        # Check if the chunk is from PDF\n",
    "        if \"[Page\" in text:\n",
    "            print(\"Source: PDF Document\")\n",
    "        else:\n",
    "            print(\"Source: Text Document\")\n",
    "        print(f\"Text: {text[:200]}...\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "# Test queries that should match both document types\n",
    "test_queries = [\n",
    "    \"What is the Michael Eisner problem?\",\n",
    "    \"What are the guidelines for hiring executives?\",\n",
    "    \"How many pages are in the test PDF?\",\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    test_rag_system(query)\n",
    "    print(\"\\n\" + \"=\"*100 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aimakerspace.openai_utils.prompts import (\n",
    "    UserRolePrompt,\n",
    "    SystemRolePrompt,\n",
    "    AssistantRolePrompt,\n",
    ")\n",
    "\n",
    "from aimakerspace.openai_utils.chatmodel import ChatOpenAI\n",
    "\n",
    "chat_openai = ChatOpenAI()\n",
    "user_prompt_template = \"{content}\"\n",
    "user_role_prompt = UserRolePrompt(user_prompt_template)\n",
    "system_prompt_template = (\n",
    "    \"You are an expert in {expertise}, you always answer in a kind way.\"\n",
    ")\n",
    "system_role_prompt = SystemRolePrompt(system_prompt_template)\n",
    "\n",
    "messages = [\n",
    "    system_role_prompt.create_message(expertise=\"Python\"),\n",
    "    user_role_prompt.create_message(\n",
    "        content=\"What is the best way to write a loop?\"\n",
    "    ),\n",
    "]\n",
    "\n",
    "response = chat_openai.run(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_PROMPT_TEMPLATE = \"\"\" \\\n",
    "Use the provided context to answer the user's query.\n",
    "\n",
    "You may not answer the user's query unless there is specific context in the following text.\n",
    "\n",
    "If you do not know the answer, or cannot answer, please respond with \"I don't know\".\n",
    "\"\"\"\n",
    "\n",
    "rag_prompt = SystemRolePrompt(RAG_PROMPT_TEMPLATE)\n",
    "\n",
    "USER_PROMPT_TEMPLATE = \"\"\" \\\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "User Query:\n",
    "{user_query}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "user_prompt = UserRolePrompt(USER_PROMPT_TEMPLATE)\n",
    "\n",
    "class RetrievalAugmentedQAPipeline:\n",
    "    def __init__(self, llm: ChatOpenAI(), vector_db_retriever: VectorDatabase) -> None:\n",
    "        self.llm = llm\n",
    "        self.vector_db_retriever = vector_db_retriever\n",
    "\n",
    "    def run_pipeline(self, user_query: str) -> str:\n",
    "    # 1. Retrieve relevant context\n",
    "    context_list = self.vector_db_retriever.search_by_text(user_query, k=4)\n",
    "\n",
    "    # 2. Format the context\n",
    "    context_prompt = \"\"\n",
    "    for context in context_list:\n",
    "        context_prompt += context[0] + \"\\n\"\n",
    "\n",
    "    # 3. Create prompts\n",
    "    formatted_system_prompt = rag_prompt.create_message()\n",
    "    formatted_user_prompt = user_prompt.create_message(\n",
    "        user_query=user_query, \n",
    "        context=context_prompt\n",
    "    )\n",
    "\n",
    "    # 4. Return response and context\n",
    "    return {\n",
    "        \"response\": self.llm.run([formatted_system_prompt, formatted_user_prompt]), \n",
    "        \"context\": context_list\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieval_augmented_qa_pipeline = RetrievalAugmentedQAPipeline(\n",
    "    vector_db_retriever=vector_db,\n",
    "    llm=chat_openai\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': \"The 'Michael Eisner Memorial Weak Executive Problem' refers to the tendency of a CEO or founder to hire weak executives in the area where they themselves excel, in order to maintain control and relevance in that function. This phenomenon occurs when a CEO, who has a strong background in a specific area (like product management, sales, or marketing), hires a less capable individual to lead that same function, enabling the CEO to continue positioning themselves as the key authority. The context illustrates this with the example of Michael Eisner, the former CEO of Disney, who struggled with leading ABC after acquiring it, emphasizing the risks of such hiring practices.\",\n",
       " 'context': [('ordingly.\\nSeventh, when hiring the executive to run your former specialty, be\\ncareful you don’t hire someone weak on purpose.\\nThis sounds silly, but you wouldn’t believe how oaen it happens.\\nThe CEO who used to be a product manager who has a weak\\nproduct management executive. The CEO who used to be in\\nsales who has a weak sales executive. The CEO who used to be\\nin marketing who has a weak marketing executive.\\nI call this the “Michael Eisner Memorial Weak Executive Problem” — aaer the CEO of Disney who had previously been a brilliant TV network executive. When he bought ABC at Disney, it\\npromptly fell to fourth place. His response? “If I had an extra\\ntwo days a week, I could turn around ABC myself.” Well, guess\\nwhat, he didn’t have an extra two days a week.\\nA CEO — or a startup founder — oaen has a hard time letting\\ngo of the function that brought him to the party. The result: you\\nhire someone weak into the executive role for that function so\\nthat you can continue to be “the man” — cons',\n",
       "   np.float64(0.6582125113300631)),\n",
       "  (\"[Page 1] Test PDF Document - Page 1\\nThis is a sample PDF created for testing the RAG system.\\nThe Michael Eisner problem is discussed in this document.\\nIt relates to CEOs who hire weak executives in their former specialty.\\n\\n[Page 2] Test PDF Document - Page 2\\nMore information about executive hiring:\\n1. Always hire strong executives\\n2. Don't micromanage unnecessarily\\n3. Focus on their strengths\\n\\n\",\n",
       "   np.float64(0.6074098784351786)),\n",
       "  ('m. They have areas where they are truly deXcient in judgment or skill set. That’s just life. Almost nobody is brilliant\\nat everything. When hiring and when Hring executives, you\\nmust therefore focus on strength rather than lack of weakness. Everybody has severe weaknesses even if you can’t see\\nthem yet. When managing, it’s oaen useful to micromanage and\\nto provide remedial training around these weaknesses. Doing so\\nmay make the diWerence between an executive succeeding or\\nfailing.\\nFor example, you might have a brilliant engineering executive\\nwho generates excellent team loyalty, has terriXc product judgment and makes the trains run on time. This same executive\\nmay be very poor at relating to the other functions in the company. She may generate far more than her share of cross-functional conYicts, cut herself oW from critical information, and\\nsigniXcantly impede your ability to sell and market eWectively.\\nYour alternatives are:\\n(a) Macro-manage and give her an annual or quarterly object',\n",
       "   np.float64(0.5088372362539736)),\n",
       "  ('ed?\\nIn reality — as opposed to Marc’s warped view of reality — it will\\nbe extremely helpful for Marc [if he were actually the CEO,\\nwhich he is not] to meet with the new head of engineering daily\\nwhen she comes on board and review all of her thinking and\\ndecisions. This level of micromanagement will accelerate her\\ntraining and improve her long-term eWectiveness. It will make\\nher seem smarter to the rest of the organization which will build\\ncredibility and conXdence while she comes up to speed. Micromanaging new executives is generally a good idea for a limited\\nperiod of time.\\nHowever, that is not the only time that it makes sense to micro66 The Pmarca Blog Archives\\nmanage executives. It turns out that just about every executive\\nin the world has a few things that are seriously wrong with\\nthem. They have areas where they are truly deXcient in judgment or skill set. That’s just life. Almost nobody is brilliant\\nat everything. When hiring and when Hring executives, you\\nmust therefore focus o',\n",
       "   np.float64(0.4790366940597922))]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieval_augmented_qa_pipeline.run_pipeline(\"What is the 'Michael Eisner Memorial Weak Executive Problem'?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
