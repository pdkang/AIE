{"questions": {"467a48aa-4615-44e1-ac07-fa0f0b8774af": "What is the primary factor that determines the quality of a resulting model when training a system?", "1dc36b11-2682-4985-93cb-d9600bd5777a": "How many lines of Python code are typically needed to train a basic version of a powerful system?", "d12b5e95-b1ca-4764-a59c-299f8cb5c4e9": "Which organizations have produced models better than GPT-3 in the past year?", "859ac409-d47f-4591-9ee9-fe1b4a0d2400": "What is the estimated training cost for large language models as mentioned in the context?", "a68310b4-0cd5-4010-9306-749e35617721": "What comparison does the author make to illustrate the difficulty of training an LLM?", "25e306ed-a912-4995-9313-c1fb6263048a": "As of January of this year, what was the author's perception of the feasibility of running a useful LLM on personal computers?", "39e86d7d-a5a7-459e-a2bd-10fa19b63c9d": "What significant event occurred in February related to Meta and Llama?", "02a53912-ffca-4cc3-84f3-9a984341c19b": "How did the release of Llama 2 in July differ from the original Llama in terms of commercial use?", "6abfb2bc-669e-41f4-9991-51ba249d0677": "What is the name of the model that the author runs on their iPhone?", "e8a46c21-4f8e-40b7-a693-77b40b8f55c6": "How can hobbyists create their own fine-tuned models according to the context?", "93aa40f5-11c3-415d-afc3-ec7ded3c5718": "What is the role of the Hugging Face Open LLM Leaderboard in the ecosystem of model training and sharing?", "9df3bd73-456f-4c8c-8688-36ea3e98a455": "How do fine-tuned community models compare to foundation models in terms of performance and licensing?", "c878a831-0d97-49dc-9638-abf7283c1b42": "What significant advancements have been made in AI models since the release of GPT-4 in March?", "f6ddea37-e03c-4643-a43c-335fdb46949b": "What are the claims made by Google\u2019s Gemini Ultra regarding its capabilities compared to GPT-4?", "3f7720a5-814d-43fb-9e87-611b41f56631": "What challenges do computer scientists and software engineers face when working with large language models (LLMs)?", "53f6d585-4740-4dc4-9890-f125b9f17a88": "Why is it difficult to evaluate the performance of LLMs according to the context provided?", "a1fa8dfb-0c1a-4ee0-a388-0c6c43bda7a3": "What challenges does the author face when evaluating the strengths and weaknesses of an LLM?", "d9100fb6-6461-4b9c-98d9-1744bd19900c": "How does the author feel about the current state of prompting and its effectiveness in working with LLMs?", "f945fc61-853f-4b8d-8679-1602ddcf43c9": "What unexpected capabilities have been discovered in LLMs that even their trainers did not anticipate?", "4aa3fbb7-2a59-4f3f-a583-c1bef273034e": "Is there a possibility that ChatGPT's performance changes in December due to its hidden system prompt and the nature of user interactions during the holiday season?", "402c2795-a8b1-4bca-8a9a-cf01e1e227aa": "What is the term coined by the author to describe the issue of manipulating responses from AI systems?", "bcbc17d0-a644-4e60-a268-f2b0bc625746": "How does the author suggest that offering incentives can affect the quality of answers provided by AI?", "ea7b5c3b-f810-4b85-ac26-062d37274a39": "Why is it important for language models to be gullible in certain contexts?", "186fec96-f514-45f0-a06e-5258e0d68268": "What are the potential drawbacks of having an AI personal assistant that believes everything it is told?"}, "relevant_contexts": {"467a48aa-4615-44e1-ac07-fa0f0b8774af": ["2e3a9869-d7eb-4c46-bbb5-d2208d8abacc"], "1dc36b11-2682-4985-93cb-d9600bd5777a": ["2e3a9869-d7eb-4c46-bbb5-d2208d8abacc"], "d12b5e95-b1ca-4764-a59c-299f8cb5c4e9": ["d4276663-74e1-4801-8ae2-8e36288f9d1c"], "859ac409-d47f-4591-9ee9-fe1b4a0d2400": ["d4276663-74e1-4801-8ae2-8e36288f9d1c"], "a68310b4-0cd5-4010-9306-749e35617721": ["f7e03256-052f-4f59-8e47-82030661fa7b"], "25e306ed-a912-4995-9313-c1fb6263048a": ["f7e03256-052f-4f59-8e47-82030661fa7b"], "39e86d7d-a5a7-459e-a2bd-10fa19b63c9d": ["5f3f1180-3654-4d93-b247-e8bdf13f1e4a"], "02a53912-ffca-4cc3-84f3-9a984341c19b": ["5f3f1180-3654-4d93-b247-e8bdf13f1e4a"], "6abfb2bc-669e-41f4-9991-51ba249d0677": ["30944a8d-8922-4c80-817e-d1c1877474a7"], "e8a46c21-4f8e-40b7-a693-77b40b8f55c6": ["30944a8d-8922-4c80-817e-d1c1877474a7"], "93aa40f5-11c3-415d-afc3-ec7ded3c5718": ["429307a7-5127-4c58-9bb8-ab500eaeadaa"], "9df3bd73-456f-4c8c-8688-36ea3e98a455": ["429307a7-5127-4c58-9bb8-ab500eaeadaa"], "c878a831-0d97-49dc-9638-abf7283c1b42": ["a615068f-598b-4bdc-9e9f-36ac723bc501"], "f6ddea37-e03c-4643-a43c-335fdb46949b": ["a615068f-598b-4bdc-9e9f-36ac723bc501"], "3f7720a5-814d-43fb-9e87-611b41f56631": ["ee3d543f-9360-443f-b64b-ba60c27d13c1"], "53f6d585-4740-4dc4-9890-f125b9f17a88": ["ee3d543f-9360-443f-b64b-ba60c27d13c1"], "a1fa8dfb-0c1a-4ee0-a388-0c6c43bda7a3": ["571d2a7d-1031-47cd-9f55-b1e30c62792e"], "d9100fb6-6461-4b9c-98d9-1744bd19900c": ["571d2a7d-1031-47cd-9f55-b1e30c62792e"], "f945fc61-853f-4b8d-8679-1602ddcf43c9": ["1f188416-b9b5-4cc1-b4b2-cbbd427343ff"], "4aa3fbb7-2a59-4f3f-a583-c1bef273034e": ["1f188416-b9b5-4cc1-b4b2-cbbd427343ff"], "402c2795-a8b1-4bca-8a9a-cf01e1e227aa": ["ee9dcb8e-7219-4c80-9ed3-979536c17e20"], "bcbc17d0-a644-4e60-a268-f2b0bc625746": ["ee9dcb8e-7219-4c80-9ed3-979536c17e20"], "ea7b5c3b-f810-4b85-ac26-062d37274a39": ["69ca31dd-d568-4e3f-8c3d-553c8bf80b34"], "186fec96-f514-45f0-a06e-5258e0d68268": ["69ca31dd-d568-4e3f-8c3d-553c8bf80b34"]}, "corpus": {"2e3a9869-d7eb-4c46-bbb5-d2208d8abacc": "Intuitively, one would expect that systems this powerful would take millions of lines of complex code. Instead, it turns out a few hundred lines of Python is genuinely enough to train a basic version!\nWhat matters most is the training  data. You need a lot of data to make these things work, and the quantity and quality of the training data appears to be the most important factor in how good the resulting model is.\nIf you can gather the right data, and afford to pay for the GPUs to train it, you can build an LLM.", "d4276663-74e1-4801-8ae2-8e36288f9d1c": "A year ago, the only organization that had released a generally useful LLM was OpenAI. We\u2019ve now seen better-than-GPT-3 class models produced by Anthropic, Mistral, Google, Meta, EleutherAI, Stability AI, TII in Abu Dhabi (Falcon), Microsoft Research, xAI, Replit, Baidu and a bunch of other organizations.\nThe training cost (hardware and electricity) is still significant\u2014initially millions of dollars, but that seems to have dropped to the tens of thousands already. Microsoft\u2019s Phi-2 claims to have used \u201c14 days on 96 A100 GPUs\u201d, which works out at around $35,000 using current Lambda pricing.", "f7e03256-052f-4f59-8e47-82030661fa7b": "So training an LLM still isn\u2019t something a hobbyist can afford, but it\u2019s no longer the sole domain of the super-rich. I like to compare the difficulty of training an LLM to that of building a suspension bridge\u2014not trivial, but hundreds of countries around the world have figured out how to do it. (Correction: Wikipedia\u2019s Suspension bridges by country category lists 44 countries).\nYou can run LLMs on your own devices\nIn January of this year, I thought it would be years before I could run a useful LLM on my own computer. GPT-3 and 3.5 were pretty much the only games in town, and I thought that even if the model weights were available it would take a $10,000+ server to run them.", "5f3f1180-3654-4d93-b247-e8bdf13f1e4a": "Then in February, Meta released Llama. And a few weeks later in March, Georgi Gerganov released code that got it working on a MacBook.\nI wrote about how Large language models are having their Stable Diffusion moment, and with hindsight that was a very good call!\nThis unleashed a whirlwind of innovation, which was accelerated further in July when Meta released Llama 2\u2014an improved version which, crucially, included permission for commercial use.\nToday there are literally thousands of LLMs that can be run locally, on all manner of different devices.", "30944a8d-8922-4c80-817e-d1c1877474a7": "I run a bunch of them on my laptop. I run Mistral 7B (a surprisingly great model) on my iPhone. You can install several different apps to get your own, local, completely private LLM. My own LLM project provides a CLI tool for running an array of different models via plugins.\nYou can even run them entirely in your browser using WebAssembly and the latest Chrome!\nHobbyists can build their own fine-tuned models\nI said earlier that building an LLM was still out of reach of hobbyists. That may be true for training from scratch, but fine-tuning one of those models is another matter entirely.", "429307a7-5127-4c58-9bb8-ab500eaeadaa": "There\u2019s now a fascinating ecosystem of people training their own models on top of these foundations, publishing those models, building fine-tuning datasets and sharing those too.\nThe Hugging Face Open LLM Leaderboard is one place that tracks these. I can\u2019t even attempt to count them, and any count would be out-of-date within a few hours.\nThe best overall openly licensed LLM at any time is rarely a foundation model: instead, it\u2019s whichever fine-tuned community model has most recently discovered the best combination of fine-tuning data.\nThis is a huge advantage for open over closed models: the closed, hosted models don\u2019t have thousands of researchers and hobbyists around the world collaborating and competing to improve them.", "a615068f-598b-4bdc-9e9f-36ac723bc501": "We don\u2019t yet know how to build GPT-4\nFrustratingly, despite the enormous leaps ahead we\u2019ve had this year, we are yet to see an alternative model that\u2019s better than GPT-4.\nOpenAI released GPT-4 in March, though it later turned out we had a sneak peak of it in February when Microsoft used it as part of the new Bing.\nThis may well change in the next few weeks: Google\u2019s Gemini Ultra has big claims, but isn\u2019t yet available for us to try out.\nThe team behind Mistral are working to beat GPT-4 as well, and their track record is already extremely strong considering their first public model only came out in September, and they\u2019ve released two significant improvements since then.", "ee3d543f-9360-443f-b64b-ba60c27d13c1": "Still, I\u2019m surprised that no-one has beaten the now almost year old GPT-4 by now. OpenAI clearly have some substantial tricks that they haven\u2019t shared yet.\nVibes Based Development\nAs a computer scientist and software engineer, LLMs are infuriating.\nEven the openly licensed ones are still the world\u2019s most convoluted black boxes. We continue to have very little idea what they can do, how exactly they work and how best to control them.\nI\u2019m used to programming where the computer does exactly what I tell it to do. Prompting an LLM is decidedly not that!\nThe worst part is the challenge of evaluating them.\nThere are plenty of benchmarks, but no benchmark is going to tell you if an LLM actually \u201cfeels\u201d right when you try it for a given task.", "571d2a7d-1031-47cd-9f55-b1e30c62792e": "I find I have to work with an LLM for a few weeks in order to get a good intuition for it\u2019s strengths and weaknesses. This greatly limits how many I can evaluate myself!\nThe most frustrating thing for me is at the level of individual prompting.\nSometimes I\u2019ll tweak a prompt and capitalize some of the words in it, to emphasize that I really want it to OUTPUT VALID MARKDOWN or similar. Did capitalizing those words make a difference? I still don\u2019t have a good methodology for figuring that out.\nWe\u2019re left with what\u2019s effectively Vibes Based Development. It\u2019s vibes all the way down.\nI\u2019d love to see us move beyond vibes in 2024!\nLLMs are really smart, and also really, really dumb", "1f188416-b9b5-4cc1-b4b2-cbbd427343ff": "On the one hand, we keep on finding new things that LLMs can do that we didn\u2019t expect\u2014and that the people who trained the models didn\u2019t expect either. That\u2019s usually really fun!\nBut on the other hand, the things you sometimes have to do to get the models to behave are often incredibly dumb.\nDoes ChatGPT get lazy in December, because its hidden system prompt includes the current date and its training data shows that people provide less useful answers coming up to the holidays?\nThe honest answer is \u201cmaybe\u201d! No-one is entirely sure, but if you give it a different date its answers may skew slightly longer.", "ee9dcb8e-7219-4c80-9ed3-979536c17e20": "Sometimes it omits sections of code and leaves you to fill them in, but if you tell it you can\u2019t type because you don\u2019t have any fingers it produces the full code for you instead.\nThere are so many more examples like this. Offer it cash tips for better answers. Tell it your career depends on it. Give it positive reinforcement. It\u2019s all so dumb, but it works!\nGullibility is the biggest unsolved problem\nI coined the term prompt injection in September last year.\n15 months later, I regret to say that we\u2019re still no closer to a robust, dependable solution to this problem.\nI\u2019ve written a ton about this already.\nBeyond that specific class of security vulnerabilities, I\u2019ve started seeing this as a wider problem of gullibility.", "69ca31dd-d568-4e3f-8c3d-553c8bf80b34": "Language Models are gullible. They \u201cbelieve\u201d what we tell them\u2014what\u2019s in their training data, then what\u2019s in the fine-tuning data, then what\u2019s in the prompt.\nIn order to be useful tools for us, we need them to believe what we feed them!\nBut it turns out a lot of the things we want to build need them not to be gullible.\nEveryone wants an AI personal assistant. If you hired a real-world personal assistant who believed everything that anyone told them, you would quickly find that their ability to positively impact your life was severely limited."}}