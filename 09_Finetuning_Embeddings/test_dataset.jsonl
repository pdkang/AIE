{"questions": {"1b99810c-8aac-4a19-a849-0d06f06a8f02": "What are AI agents commonly understood to be, according to the context provided?", "9ba318c4-0274-42d7-8d0c-f4c2c2163d55": "Why does the author believe that gullibility may hinder the development of AI agents?", "9b9ceb48-fbb1-4957-b428-098158ef0b57": "What are some examples of programming languages mentioned in the context?", "0f8fdbb4-5fcf-4ec8-8921-316d36aaa4a0": "What is one of the significant weaknesses of LLMs as described in the context?", "7d430f22-c67e-4a73-bebc-00c86caece4f": "How does the ability of LLMs to execute and debug code impact the role of software engineers?", "2d3dbc87-22ae-40db-a5f3-3f0acbc5d9d6": "What are the implications of having a Code Interpreter equivalent for fact-checking natural language?", "499f99aa-85a1-4cc5-9899-ff4df63263c0": "What advantages do software engineers have in utilizing coding interns for problem-solving?", "c2ee71a8-b331-436b-9865-51940f8b29e3": "What ethical concerns are associated with the use of unlicensed training data in machine learning models?", "0db5a42d-0cc2-40c4-943c-9a246e220cb5": "What is the main subject of the lawsuit launched by the New York Times against OpenAI and Microsoft?", "612e909d-0e02-468a-b84c-6526253740ff": "Why is the first few pages of the 69-page PDF considered particularly valuable for understanding the issues at hand?", "2e7b241d-3eae-4452-b68d-b045ea594d05": "What are the ethical implications of training AI models on individuals' content without their consent?", "c47b065b-fd39-4d54-b23e-45874fa87109": "How has the increasing quality of AI models affected employment in creative fields such as copywriting, art, and translation?", "ab634d96-0288-4ca6-b241-f7ca1024e86c": "What was the title of the article that received the highest number of visitors according to the provided analytics?", "e6fbf7ac-6c13-4a87-bcf4-c73fefaf1d93": "How many visitors did the article titled \"Leaked Google document: 'We Have No Moat, And Neither Does OpenAI'\" receive?", "86e6d744-df9f-4719-80b3-431ac10fe314": "What are embeddings and why are they considered important in the context of LLMs?", "fecda3dd-63fe-458e-990f-4d1bbeaf5e6a": "How does the new llamafile improve the process of running an LLM on a personal computer?", "765f14a7-7dbe-4299-836a-908e943a079b": "What is the significance of prompt engineering in DALL-E 3 as mentioned in the context?", "b2584613-c452-40ea-8efa-1137edaf82e2": "How does the vicuna-7b Large Language Model operate within a web browser?", "59470214-5e3a-4d0e-94a5-e4f450fd6bd9": "What topics were covered in the annotated presentations given in 2023?", "1b01de86-0454-4060-b60e-49d117834bb3": "Which podcasts featured discussions about Large Language Models?", "651548b9-aea0-4cb1-a8fa-ff73aced0a7f": "What is the main topic discussed in the article posted on December 31, 2023?", "b02f09cc-069a-41bb-b8db-164e6ad4979c": "When is the next article in the series \"LLMs annual review\" expected to be published?", "b8df8fc3-da59-4dbf-b1e3-f3471c161bd9": "What is the numerical value associated with \"ai\" in the provided context?", "1e02b1ae-b5a0-4a63-aee6-366266ee7099": "How many times is \"llms\" mentioned in the context?"}, "relevant_contexts": {"1b99810c-8aac-4a19-a849-0d06f06a8f02": ["f2d51122-c216-4944-8399-12b5e578e2f5"], "9ba318c4-0274-42d7-8d0c-f4c2c2163d55": ["f2d51122-c216-4944-8399-12b5e578e2f5"], "9b9ceb48-fbb1-4957-b428-098158ef0b57": ["e5c718f9-73dd-407f-a5f5-8aec06e6a457"], "0f8fdbb4-5fcf-4ec8-8921-316d36aaa4a0": ["e5c718f9-73dd-407f-a5f5-8aec06e6a457"], "7d430f22-c67e-4a73-bebc-00c86caece4f": ["bedf0442-6afe-48c1-a1d5-939ae67d3cec"], "2d3dbc87-22ae-40db-a5f3-3f0acbc5d9d6": ["bedf0442-6afe-48c1-a1d5-939ae67d3cec"], "499f99aa-85a1-4cc5-9899-ff4df63263c0": ["a5e9be74-4cf0-4edd-b3f6-4a51ba749757"], "c2ee71a8-b331-436b-9865-51940f8b29e3": ["a5e9be74-4cf0-4edd-b3f6-4a51ba749757"], "0db5a42d-0cc2-40c4-943c-9a246e220cb5": ["0e2d7170-a999-4036-9a6f-2f372ecf63dc"], "612e909d-0e02-468a-b84c-6526253740ff": ["0e2d7170-a999-4036-9a6f-2f372ecf63dc"], "2e7b241d-3eae-4452-b68d-b045ea594d05": ["095bb44d-f582-4e57-a8b6-a991c8843488"], "c47b065b-fd39-4d54-b23e-45874fa87109": ["095bb44d-f582-4e57-a8b6-a991c8843488"], "ab634d96-0288-4ca6-b241-f7ca1024e86c": ["1caf935c-d6e5-4457-95dd-a13f1136f2ea"], "e6fbf7ac-6c13-4a87-bcf4-c73fefaf1d93": ["1caf935c-d6e5-4457-95dd-a13f1136f2ea"], "86e6d744-df9f-4719-80b3-431ac10fe314": ["2976b45f-d733-4dc8-b95a-776a400ac096"], "fecda3dd-63fe-458e-990f-4d1bbeaf5e6a": ["2976b45f-d733-4dc8-b95a-776a400ac096"], "765f14a7-7dbe-4299-836a-908e943a079b": ["d7b32078-1356-4e5e-8561-d654edc36ba5"], "b2584613-c452-40ea-8efa-1137edaf82e2": ["d7b32078-1356-4e5e-8561-d654edc36ba5"], "59470214-5e3a-4d0e-94a5-e4f450fd6bd9": ["1fee80cc-0fd2-4189-bc6e-e508f6ac0b40"], "1b01de86-0454-4060-b60e-49d117834bb3": ["1fee80cc-0fd2-4189-bc6e-e508f6ac0b40"], "651548b9-aea0-4cb1-a8fa-ff73aced0a7f": ["65b7fb7a-ca79-43f5-91d5-3f2bc02f0687"], "b02f09cc-069a-41bb-b8db-164e6ad4979c": ["65b7fb7a-ca79-43f5-91d5-3f2bc02f0687"], "b8df8fc3-da59-4dbf-b1e3-f3471c161bd9": ["6d58fa5b-c549-4418-9f61-503e67d73afd"], "1e02b1ae-b5a0-4a63-aee6-366266ee7099": ["6d58fa5b-c549-4418-9f61-503e67d73afd"]}, "corpus": {"f2d51122-c216-4944-8399-12b5e578e2f5": "A lot of people are excited about AI agents\u2014an infuriatingly vague term that seems to be converging on \u201cAI systems that can go away and act on your behalf\u201d. We\u2019ve been talking about them all year, but I\u2019ve seen few if any examples of them running in production, despite lots of exciting prototypes.\nI think this is because of gullibility.\nCan we solve this? Honestly, I\u2019m beginning to suspect that you can\u2019t fully solve gullibility without achieving AGI. So it may be quite a while before those agent dreams can really start to come true!\nCode may be the best application\nOver the course of the year, it\u2019s become increasingly clear that writing code is one of the things LLMs are most capable of.", "e5c718f9-73dd-407f-a5f5-8aec06e6a457": "If you think about what they do, this isn\u2019t such a big surprise. The grammar rules of programming languages like Python and JavaScript are massively less complicated than the grammar of Chinese, Spanish or English.\nIt\u2019s still astonishing to me how effective they are though.\nOne of the great weaknesses of LLMs is their tendency to hallucinate\u2014to imagine things that don\u2019t correspond to reality. You would expect this to be a particularly bad problem for code\u2014if an LLM hallucinates a method that doesn\u2019t exist, the code should be useless.", "bedf0442-6afe-48c1-a1d5-939ae67d3cec": "Except... you can run generated code to see if it\u2019s correct. And with patterns like ChatGPT Code Interpreter the LLM can execute the code itself, process the error message, then rewrite it and keep trying until it works!\nSo hallucination is a much lesser problem for code generation than for anything else. If only we had the equivalent of Code Interpreter for fact-checking natural language!\nHow should we feel about this as software engineers?\nOn the one hand, this feels like a threat: who needs a programmer if ChatGPT can write code for you?", "a5e9be74-4cf0-4edd-b3f6-4a51ba749757": "On the other hand, as software engineers we are better placed to take advantage of this than anyone else. We\u2019ve all been given weird coding interns\u2014we can use our deep knowledge to prompt them to solve coding problems more effectively than anyone else can.\nThe ethics of this space remain diabolically complex\nIn September last year Andy Baio and I produced the first major story on the unlicensed training data behind Stable Diffusion.\nSince then, almost every major LLM (and most of the image generation models) have also been trained on unlicensed data.", "0e2d7170-a999-4036-9a6f-2f372ecf63dc": "Just this week, the New York Times launched a landmark lawsuit against OpenAI and Microsoft over this issue. The 69 page PDF is genuinely worth reading\u2014especially the first few pages, which lay out the issues in a way that\u2019s surprisingly easy to follow. The rest of the document includes some of the clearest explanations of what LLMs are, how they work and how they are built that I\u2019ve read anywhere.\nThe legal arguments here are complex. I\u2019m not a lawyer, but I don\u2019t think this one will be easily decided. Whichever way it goes, I expect this case to have a profound impact on how this technology develops in the future.", "095bb44d-f582-4e57-a8b6-a991c8843488": "Law is not ethics. Is it OK to train models on people\u2019s content without their permission, when those models will then be used in ways that compete with those people?\nAs the quality of results produced by AI models has increased over the year, these questions have become even more pressing.\nThe impact on human society in terms of these models is already huge, if difficult to objectively measure.\nPeople have certainly lost work to them\u2014anecdotally, I\u2019ve seen this for copywriters, artists and translators.\nThere are a great deal of untold stories here. I\u2019m hoping 2024 sees significant amounts of dedicated journalism on this topic.\nMy blog in 2023\nHere\u2019s a tag cloud for content I posted to my blog in 2023 (generated using Django SQL Dashboard):", "1caf935c-d6e5-4457-95dd-a13f1136f2ea": "The top five: ai (342), generativeai (300), llms (287), openai (86), chatgpt (78).\nI\u2019ve written a lot about this stuff!\nI grabbed a screenshot of my Plausible analytics for the year, fed that to ChatGPT Vision, told it to extract the data into a table, then got it to mix in entry titles (from a SQL query it wrote) and produced this table with it. Here are my top entries this year by amount of traffic:\n\n\n\nArticle\nVisitors\nPageviews\n\n\n\n\nBing: \u201cI will not harm you unless you harm me first\u201d\n1.1M\n1.3M\n\n\nLeaked Google document: \u201cWe Have No Moat, And Neither Does OpenAI\u201d\n132k\n162k\n\n\nLarge language models are having their Stable Diffusion moment\n121k\n150k\n\n\nPrompt injection: What\u2019s the worst that can happen?\n79.8k\n95.9k", "2976b45f-d733-4dc8-b95a-776a400ac096": "Embeddings: What they are and why they matter\n61.7k\n79.3k\n\n\nCatching up on the weird world of LLMs\n61.6k\n85.9k\n\n\nllamafile is the new best way to run an LLM on your own computer\n52k\n66k\n\n\nPrompt injection explained, with video, slides, and a transcript\n51k\n61.9k\n\n\nAI-enhanced development makes me more ambitious with my projects\n49.6k\n60.1k\n\n\nUnderstanding GPT tokenizers\n49.5k\n61.1k\n\n\nExploring GPTs: ChatGPT in a trench coat?\n46.4k\n58.5k\n\n\nCould you train a ChatGPT-beating model for $85,000 and run it in a browser?\n40.5k\n49.2k\n\n\nHow to implement Q&A against your documentation with GPT3, embeddings and Datasette\n37.3k\n44.9k\n\n\nLawyer cites fake cases invented by ChatGPT, judge is not amused\n37.1k\n47.4k", "d7b32078-1356-4e5e-8561-d654edc36ba5": "Now add a walrus: Prompt engineering in DALL-E 3\n32.8k\n41.2k\n\n\nWeb LLM runs the vicuna-7b Large Language Model entirely in your browser, and it\u2019s very impressive\n32.5k\n38.2k\n\n\nChatGPT can\u2019t access the internet, even though it really looks like it can\n30.5k\n34.2k\n\n\nStanford Alpaca, and the acceleration of on-device large language model development\n29.7k\n35.7k\n\n\nRun Llama 2 on your own Mac using LLM and Homebrew\n27.9k\n33.6k\n\n\nMidjourney 5.1\n26.7k\n33.4k\n\n\nThink of language models like ChatGPT as a \u201ccalculator for words\u201d\n25k\n31.8k\n\n\nMulti-modal prompt injection image attacks against GPT-4V\n23.7k\n27.4k", "1fee80cc-0fd2-4189-bc6e-e508f6ac0b40": "I also gave a bunch of talks and podcast appearances. I\u2019ve started habitually turning my talks into annotated presentations\u2014here are my best from 2023:\n\nPrompt injection explained, with video, slides, and a transcript\nCatching up on the weird world of LLMs\nMaking Large Language Models work for you\nOpen questions for AI engineering\nEmbeddings: What they are and why they matter\nFinancial sustainability for open source projects at GitHub Universe\n\nAnd in podcasts:\n\n\nWhat AI can do for you on the Theory of Change\n\nWorking in public on Path to Citus Con\n\nLLMs break the internet on the Changelog\n\nTalking Large Language Models on Rooftop Ruby\n\nThoughts on the OpenAI board situation on Newsroom Robots", "65b7fb7a-ca79-43f5-91d5-3f2bc02f0687": "Industry\u2019s Tardy Response to the AI Prompt Injection Vulnerability on RedMonk Conversations\n\n\nPosted 31st December 2023 at 11:59 pm \u00b7 Follow me on Mastodon or Twitter or subscribe to my newsletter\n\n\nMore recent articles\n\nURL-addressable Pyodide Python environments - 13th February 2025\nUsing pip to install a Large Language Model that's under 100MB - 7th February 2025\nOpenAI o3-mini, now available in LLM - 31st January 2025\n\n\n \n\n\nThis is Stuff we figured out about AI in 2023 by Simon Willison, posted on 31st December 2023.\n\nPart of series LLMs annual review\n\nStuff we figured out about AI in 2023 - Dec. 31, 2023, 11:59 p.m. \nThings we learned about LLMs in 2024 - Dec. 31, 2024, 6:07 p.m. \n\n\n\n            blogging\n            68", "6d58fa5b-c549-4418-9f61-503e67d73afd": "ai\n            1096\n\n\n            generative-ai\n            940\n\n\n            llms\n            928\n\nNext: Tom Scott, and the formidable power of escalating streaks\nPrevious: Last weeknotes of 2023\n\n\n \n \n\n\nColophon\n\u00a9\n2002\n2003\n2004\n2005\n2006\n2007\n2008\n2009\n2010\n2011\n2012\n2013\n2014\n2015\n2016\n2017\n2018\n2019\n2020\n2021\n2022\n2023\n2024\n2025"}}